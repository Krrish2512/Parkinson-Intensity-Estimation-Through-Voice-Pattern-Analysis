{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow6G8s0REkw_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXbMFhxPEkxL"
   },
   "source": [
    "We will import more libraries/dependencies as per needed further in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "agihoCQwEkxY",
    "outputId": "252cdf46-af32-44c9-8f86-6741b068bbe5"
   },
   "outputs": [],
   "source": [
    "park = pd.read_csv(r\"better_data.csv\")\n",
    "park.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI3U_0Z_6J_1"
   },
   "outputs": [],
   "source": [
    "park.drop(columns=['test_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ii3ZwxWf1l6z",
    "outputId": "b8ca2fd7-ae4e-41cf-bfcd-f69ec730df9c"
   },
   "outputs": [],
   "source": [
    "print(park['DFA'].max(), \" \", park['DFA'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJkfU5iYEkxf"
   },
   "source": [
    "## Important Parameters in our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziUsFyL6Ekxh"
   },
   "source": [
    "Jitter:\n",
    "\n",
    "Definition: Jitter is a measure of the frequency variation in consecutive periods of a sound waveform.\n",
    "In the Dataset: The dataset includes several jitter-related features, such as Jitter(%), Jitter(Abs), Jitter:RAP (Relative Average Perturbation), Jitter:PPQ5 (Five-Point Period Perturbation Quotient), and Jitter:DDP (Jitter:RAP * 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UL2N57pEkxj"
   },
   "source": [
    "Shimmer:\n",
    "\n",
    "Definition: Shimmer is a measure of the amplitude variation in consecutive periods of a sound waveform.\n",
    "In the Dataset: The dataset includes several shimmer-related features, such as Shimmer, Shimmer(dB) (Shimmer in decibels), Shimmer:APQ3 (Amplitude Perturbation Quotient, three-point), Shimmer:APQ5 (Amplitude Perturbation Quotient, five-point), Shimmer:APQ11 (Amplitude Perturbation Quotient, eleven-point), and Shimmer:DDA (Shimmer:APQ11 * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDuthLbOEkxq"
   },
   "source": [
    "Total UPDRS (Unified Parkinson's Disease Rating Scale):\n",
    "\n",
    "Definition: The UPDRS is a widely used rating scale that assesses the severity of Parkinson's disease. The total UPDRS is the sum of scores from various sections of the UPDRS, including assessments of mentation, behavior, mood, activities of daily living, and motor function.\n",
    "In the Dataset: The dataset includes a column named \"total_UPDRS,\" which represents the total UPDRS score for each individual.\n",
    "Motor UPDRS (Motor Section of UPDRS):\n",
    "\n",
    "Definition: The motor section of the UPDRS specifically focuses on evaluating motor symptoms associated with Parkinson's disease, including tremors, rigidity, bradykinesia, and posture instability.\n",
    "In the Dataset: The dataset includes a column named \"motor_UPDRS,\" which represents the score related to the motor symptoms in the UPDRS for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "iZmuTY1vEkxs",
    "outputId": "da0fa9bf-7944-464c-9f27-2346fd4ad842"
   },
   "outputs": [],
   "source": [
    "park['age'].value_counts().unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dr_4chgLEkxv",
    "outputId": "c4d6b715-f399-4341-a5cb-93ca55cb55c9"
   },
   "outputs": [],
   "source": [
    "park.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHsYbMxqEkx3",
    "outputId": "fad99097-f3cd-464d-d6f7-501a1d152ef8"
   },
   "outputs": [],
   "source": [
    "park.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RIPSHNAEkx6",
    "outputId": "3eef0491-b6ba-43d8-e102-2b6c12f6e4c3"
   },
   "outputs": [],
   "source": [
    "park.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-jxaEDLEkx8"
   },
   "outputs": [],
   "source": [
    "# park['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miEmYd3OEkyG"
   },
   "outputs": [],
   "source": [
    "# X = park.drop(columns = ['status', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1sowr_QEkyI"
   },
   "outputs": [],
   "source": [
    "# X = park.drop('status', 'name', axis=1)\n",
    "# Y = park['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "FDkRSuwvEkyN",
    "outputId": "fdfcce5f-6196-426f-dca3-c443367a53ac"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=park, x='Jitter(%)', y='Shimmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y25XF92KEkyQ"
   },
   "outputs": [],
   "source": [
    "# sns.scatterplot(data = park, x = 'subject#', y = 'combined_UPDRS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SLY8RHMEkyZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "7sSAjNbOEkyb",
    "outputId": "7eee2936-f5b6-4665-95b8-4b1ffd4da492"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(park['age'], park['Jitter(%)'], park['Shimmer'])\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Jitter(%)')\n",
    "ax.set_zlabel('Shimmer')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "ugYUjsXIEkye",
    "outputId": "2c80fe95-bd5f-4e09-8711-e79ba88d9229"
   },
   "outputs": [],
   "source": [
    "sns.stripplot(data = park, x = 'sex', y = 'Jitter(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "2TRa8aVwEkyp",
    "outputId": "29558115-711c-4bef-dead-e068b71ef953"
   },
   "outputs": [],
   "source": [
    "sns.stripplot(data = park, x = 'age', y = 'Jitter(%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "BgTZ_3ZbEkys",
    "outputId": "c32baac6-5461-40df-e0af-cc1d5123aeb0"
   },
   "outputs": [],
   "source": [
    "sns.stripplot(data  =park, x = 'sex', y = 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3frEz_EYEkyv"
   },
   "source": [
    "Below is the pairplot between age, sex, motor_UPDRS and total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QL9VToxEEkyx",
    "outputId": "782e1453-e8ac-4b66-ceea-a59c931a7cac"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(park[['age', 'sex', 'motor_UPDRS', 'total_UPDRS']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gItawirzEky8"
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxBUae5MEky9"
   },
   "source": [
    "Here we visualize the correalation between different variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "B3k63Gp2Eky_",
    "outputId": "2f9fa3f0-e333-4ba0-d874-d6cde2fe0081"
   },
   "outputs": [],
   "source": [
    "corr = park.corr()\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "KApWzrgPEkzJ",
    "outputId": "22117994-f2aa-43d2-da72-b3d4252768ca"
   },
   "outputs": [],
   "source": [
    "\n",
    "cmap = sns.color_palette(\"BuGn\", as_cmap=True)\n",
    "# cmap = cmap.reversed()\n",
    "sns.heatmap(corr, fmt = \".2f\", linewidth = 0.1, cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxAw6fgXEkzL"
   },
   "source": [
    "We can see that all the jitter variables highly correlate with Shimmer variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gbo3yvyyEkzN"
   },
   "source": [
    "Since the correlation between out two target variables, total_UPDRS and motor_UPDRS is very high, we can combine them into one, using feature enggineering, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "bJzYZdkXEkzP",
    "outputId": "74c51d86-73e9-4b3f-d3e3-bbb8ebf51a49"
   },
   "outputs": [],
   "source": [
    "park['combined_UPDRS'] = (park['total_UPDRS']+park['motor_UPDRS'])/2\n",
    "park = park.drop(columns = ['total_UPDRS', 'motor_UPDRS'])\n",
    "\n",
    "park.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "9jsRLeDz8kCH",
    "outputId": "8840c066-3224-43b3-c224-592bbc23299d"
   },
   "outputs": [],
   "source": [
    "# prompt: sort the df based on combined_updrs\n",
    "\n",
    "park.sort_values(by=['combined_UPDRS'], inplace=True)\n",
    "park.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjeCnV5R1ov8",
    "outputId": "1849da8e-17a6-4252-cdbe-6d022aca6d80"
   },
   "outputs": [],
   "source": [
    "print(park['combined_UPDRS'].min(),\", \", park['combined_UPDRS'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "tCk_UDK5EkzX",
    "outputId": "cbdc02b6-f03e-4101-f59f-ee57615dd890"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = park, x = 'age', y = 'combined_UPDRS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juOjaUKhEkzb"
   },
   "outputs": [],
   "source": [
    "Y = park['combined_UPDRS']\n",
    "X = park.drop(columns  = ['combined_UPDRS', 'subject#'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA39xSfxEkzi"
   },
   "source": [
    "## PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSTNkp8AEkzk"
   },
   "source": [
    "PCA reduces the number of variables of a data set, while preserving as much information as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-sXB8FEEkzn",
    "outputId": "068422cd-1ff2-4200-885c-a2eaae040068"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.90) #0.90 means I'm asking PCA to give me 90% of the information, i don't care how many PCs you have, just retain 90% of information.\n",
    "# Fit and transform your data\n",
    "X_pca = pca.fit_transform(X)\n",
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained variance ratio:\", explained_variance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "408KsbNZEkzq",
    "outputId": "a6de3eca-7bc3-4555-eab4-873230920cef"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzdnIzXAEk18",
    "outputId": "f5e6b1cb-9c1b-4d02-b8e1-3a8d1f8428a3"
   },
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cYhzNPPEk2A"
   },
   "source": [
    "As we see, PCA reduced our dataset with 15 features to just 1 feature.\n",
    "This might not be very beneficial, beacause PCA is used for dimensionality reduction, and 15 features is not a big dimension.\n",
    "So, we will avoid PCA as for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZ-9_87aEk2G"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8I6Sx_MEk2O"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "O2E2qjuZEk2R",
    "outputId": "7de1ddb3-32a9-4a4c-b08f-5550762f7e9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KVW731JEk2U",
    "outputId": "4d9a9e41-bfb1-43e4-8b56-97f4aec8216d"
   },
   "outputs": [],
   "source": [
    "print(\"MSE_LR = \",mean_squared_error(Y_test, lr.predict(X_test)))\n",
    "print(\"RMSE_LR = \",np.sqrt(mean_squared_error(Y_test, lr.predict(X_test))))\n",
    "print(\"MAE_LR = \",mean_absolute_error(Y_test, lr.predict(X_test)))\n",
    "print(\"R2_LR = \",r2_score(Y_test, lr.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svVWdpvoEk2c"
   },
   "source": [
    "## Elastic Net Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "hzAq48sBEk2e",
    "outputId": "8c6d426c-f0e9-4c95-e19b-b3cb7047f939"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en = ElasticNet()\n",
    "en.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tav5IgaEk2g",
    "outputId": "c60d4432-ab6b-4f61-be2b-a5e0ebc11132"
   },
   "outputs": [],
   "source": [
    "print(\"MSE_EN = \",mean_squared_error(Y_test, en.predict(X_test)))\n",
    "print(\"RMSE_EN = \",np.sqrt(mean_squared_error(Y_test, en.predict(X_test))))\n",
    "print(\"MAE_EN = \",mean_absolute_error(Y_test, en.predict(X_test)))\n",
    "print(\"R2_EN = \",r2_score(Y_test, en.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIQMXZKmEk2m"
   },
   "source": [
    "R2 score for Elastic Net is closer to 0, and mean absolute and mean squared, both error are also considerably higher for elastic net.\n",
    "\n",
    "In conclusion, Elastic Net is not a good measure for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgocDZwqEk2q"
   },
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "axUqyQPuEk2s",
    "outputId": "400a4641-850e-4d7a-eedf-8a74c9a45e79"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eB0YG-fqEk6R",
    "outputId": "ebde2eda-6a4e-4d45-e7d1-dd99707e55b3"
   },
   "outputs": [],
   "source": [
    "print(\"MSE_RFR = \",mean_squared_error(Y_test, rfr.predict(X_test)))\n",
    "print(\"RMSE_RFR = \",np.sqrt(mean_squared_error(Y_test, rfr.predict(X_test))))\n",
    "print(\"MAE_RFR = \",mean_absolute_error(Y_test, rfr.predict(X_test)))\n",
    "print(\"R2_RFR = \",r2_score(Y_test, rfr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHZGHqoEEk6V"
   },
   "source": [
    "R² measures the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R² indicates a better fit.\n",
    "\n",
    "R² closer to 1 indicates  good fit, meaning the model is able to explain the variance better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E36Fwp4Ek6Z"
   },
   "source": [
    "## Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R54e8g9wEk6b"
   },
   "source": [
    "Before combining all jitter variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoLyE_WJEk6d"
   },
   "source": [
    "MSE_LR =  70.60733594551309\n",
    "RMSE_LR =  8.402817143405722\n",
    "MAE_LR =  7.019038615554898\n",
    "R2_LR =  0.1684497596409289\n",
    "\n",
    "MSE_EN =  75.40984564673356\n",
    "RMSE_EN =  8.68388424881018\n",
    "MAE_EN =  7.386348448565772\n",
    "R2_EN =  0.1118900829033953\n",
    "\n",
    "MSE_RFR =  2.1071390993467753\n",
    "RMSE_RFR =  1.4515988079861375\n",
    "MAE_RFR =  0.6778182274532043\n",
    "R2_RFR =  0.9751839946789105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj28y1uJEk6f"
   },
   "source": [
    "After combining all jitter variables, LR and EN metrics remain same, but RFR metrics worsen slightly, so we will avoid taking average of all jitter variables and combing them into one\n",
    "\n",
    "MSE_LR =  70.60733594551309\n",
    "RMSE_LR =  8.402817143405722\n",
    "MAE_LR =  7.019038615554898\n",
    "R2_LR =  0.1684497596409289\n",
    "\n",
    "MSE_EN =  75.40984564673356\n",
    "RMSE_EN =  8.68388424881018\n",
    "MAE_EN =  7.386348448565772\n",
    "R2_EN =  0.1118900829033953\n",
    "\n",
    "MSE_RFR =  2.941390993467753\n",
    "RMSE_RFR =  1.7415988079861375\n",
    "MAE_RFR =  0.7078182274532043\n",
    "R2_RFR =  0.9621839946789105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiLNemf1Ek6h"
   },
   "source": [
    "After using PCA, and using X_pca for training our data, the metrics come out to be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxujQenfEk6i"
   },
   "source": [
    "MSE_LR =  84.40199403224499\n",
    "RMSE_LR =  9.187055786934408\n",
    "MAE_LR =  7.7413866338340735\n",
    "R2_LR =  0.005988577752617408\n",
    "\n",
    "MSE_EN =  84.40313712026162\n",
    "RMSE_EN =  9.18711799860335\n",
    "MAE_EN =  7.740798931123667\n",
    "R2_EN =  0.0059751154812789364\n",
    "\n",
    "MSE_RFR =  13.392135907713705\n",
    "RMSE_RFR =  3.659526732750248\n",
    "MAE_RFR =  1.5755579988655728\n",
    "R2_RFR =  0.8422793653966156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPBAywvfEk6k",
    "outputId": "4fc133c3-7448-4c29-c028-ffa4a6d4f562"
   },
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pC9PUx8Ek6n",
    "outputId": "aeb93b5b-30a5-4ea5-e12c-30e839aae516"
   },
   "outputs": [],
   "source": [
    "importances = rfr.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUZapyPIEk6q",
    "outputId": "5aa6ee83-004a-43d0-d586-5b23c55d1897"
   },
   "outputs": [],
   "source": [
    "importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcQ-2sYQEk6s",
    "outputId": "599ece82-4b4b-4c70-ca7a-deef95a4cbca"
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'Features': X.columns, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9gilDxNjEk6v",
    "outputId": "d14a97b1-933f-4937-8370-d7ac52a9e500"
   },
   "outputs": [],
   "source": [
    "plt.barh(feature_importances['Features'], feature_importances['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilg1jGE0Ek6y"
   },
   "source": [
    "As we can seee from the above graph, in the given dataset, the feature with highest importance is age. Actually it makes sense too, since it's true that PD is more commonly diagnosed in older individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd8mD1UgEk60",
    "outputId": "185fa17e-4709-4159-a772-1804ba57525b"
   },
   "outputs": [],
   "source": [
    "# Identify the most important features\n",
    "top_features = feature_importances.head(5)['Features'].tolist()\n",
    "print(top_features)\n",
    "\n",
    "# Select only the top features for modeling\n",
    "X_top_features = X[top_features]\n",
    "\n",
    "# Retrain the model using only the top features\n",
    "X_train_top, X_test_top, Y_train, Y_test = train_test_split(X_top_features, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "rfr_top = RandomForestRegressor()\n",
    "rfr_top.fit(X_train_top, Y_train)\n",
    "\n",
    "# Evaluate the model with top features\n",
    "print(\"MSE_RFR_TopFeatures = \", mean_squared_error(Y_test, rfr_top.predict(X_test_top)))\n",
    "print(\"RMSE_RFR_TopFeatures = \", np.sqrt(mean_squared_error(Y_test, rfr_top.predict(X_test_top))))\n",
    "print(\"MAE_RFR_TopFeatures = \", mean_absolute_error(Y_test, rfr_top.predict(X_test_top)))\n",
    "print(\"R2_RFR_TopFeatures = \", r2_score(Y_test, rfr_top.predict(X_test_top)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sIyEwiYEk63"
   },
   "source": [
    "Before using feature importance:\n",
    "\n",
    "MSE_RFR =  2.1071390993467753\n",
    "RMSE_RFR =  1.4515988079861375\n",
    "MAE_RFR =  0.6778182274532043\n",
    "R2_RFR =  0.9751839946789105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Rfk2unEk66"
   },
   "source": [
    "After using feature importance with top 5 features:\n",
    "\n",
    "MSE_RFR_TopFeatures =  1.6492246470676404\n",
    "RMSE_RFR_TopFeatures =  1.2842214166831358\n",
    "MAE_RFR_TopFeatures =  0.46437770476460627\n",
    "R2_RFR_TopFeatures =  0.9805769027635669\n",
    "\n",
    "If we use 4, or 6 top features, our accuracy decreases, so the best parameter is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpRMpwDUEk6-",
    "outputId": "5f3f8c42-598b-4d9c-e554-41bdcb9fe8a4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Metrics before combining UPDRS scores\n",
    "scenario_names_before_combining = ['Linear Regression', 'Elastic Net', 'Random Forest']\n",
    "mse_before_combining = [70.61, 75.41, 2.11]\n",
    "rmse_before_combining = [8.40, 8.68, 1.45]\n",
    "mae_before_combining = [7.02, 7.39, 0.68]\n",
    "r2_before_combining = [0.17, 0.11, 0.98]\n",
    "\n",
    "# Metrics after combining UPDRS scores\n",
    "scenario_names_after_combining = ['Linear Regression', 'Elastic Net', 'Random Forest']\n",
    "mse_after_combining = [70.61, 75.41, 2.94]\n",
    "rmse_after_combining = [8.40, 8.68, 1.74]\n",
    "mae_after_combining = [7.02, 7.39, 0.71]\n",
    "r2_after_combining = [0.17, 0.11, 0.96]\n",
    "\n",
    "# Metrics after using PCA\n",
    "scenario_names_after_pca = ['Linear Regression', 'Elastic Net', 'Random Forest']\n",
    "mse_after_pca = [84.40, 84.40, 13.39]\n",
    "rmse_after_pca = [9.19, 9.19, 3.66]\n",
    "mae_after_pca = [7.74, 7.74, 1.58]\n",
    "r2_after_pca = [0.01, 0.01, 0.84]\n",
    "\n",
    "# Metrics after using Feature Importance\n",
    "scenario_names_after_feature_importance = ['Random Forest (All Features)', 'Random Forest (Top 5 Features)']\n",
    "mse_after_feature_importance = [2.94, 1.65]\n",
    "rmse_after_feature_importance = [1.74, 1.28]\n",
    "mae_after_feature_importance = [0.71, 0.46]\n",
    "r2_after_feature_importance = [0.96, 0.98]\n",
    "\n",
    "# Create DataFrames\n",
    "df_before_combining = pd.DataFrame({\n",
    "    'Scenario': scenario_names_before_combining,\n",
    "    'MSE': mse_before_combining,\n",
    "    'RMSE': rmse_before_combining,\n",
    "    'MAE': mae_before_combining,\n",
    "    'R2': r2_before_combining\n",
    "})\n",
    "\n",
    "df_after_combining = pd.DataFrame({\n",
    "    'Scenario': scenario_names_after_combining,\n",
    "    'MSE': mse_after_combining,\n",
    "    'RMSE': rmse_after_combining,\n",
    "    'MAE': mae_after_combining,\n",
    "    'R2': r2_after_combining\n",
    "})\n",
    "\n",
    "df_after_pca = pd.DataFrame({\n",
    "    'Scenario': scenario_names_after_pca,\n",
    "    'MSE': mse_after_pca,\n",
    "    'RMSE': rmse_after_pca,\n",
    "    'MAE': mae_after_pca,\n",
    "    'R2': r2_after_pca\n",
    "})\n",
    "\n",
    "df_after_feature_importance = pd.DataFrame({\n",
    "    'Scenario': scenario_names_after_feature_importance,\n",
    "    'MSE': mse_after_feature_importance,\n",
    "    'RMSE': rmse_after_feature_importance,\n",
    "    'MAE': mae_after_feature_importance,\n",
    "    'R2': r2_after_feature_importance\n",
    "})\n",
    "\n",
    "# Display the tables\n",
    "print(\"Metrics Before Combining UPDRS Scores:\")\n",
    "print(tabulate(df_before_combining, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "print(\"\\nMetrics After Combining UPDRS Scores:\")\n",
    "print(tabulate(df_after_combining, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "print(\"\\nMetrics After Using PCA:\")\n",
    "print(tabulate(df_after_pca, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "print(\"\\nMetrics After Using Feature Importance:\")\n",
    "print(tabulate(df_after_feature_importance, headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rizEq0CEk7E"
   },
   "source": [
    "## Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqA3pqBjEk7H"
   },
   "source": [
    "PCA (Principal Component Analysis):\n",
    "\n",
    "I observed that applying PCA to reduce the dimensionality from 15 features to 1 might not be very beneficial. It seems that PCA is more effective when dealing with a larger number of features.\n",
    "\n",
    "\n",
    "Combining UPDRS Scores:\n",
    "\n",
    "I decided to combine \"total_UPDRS\" and \"motor_UPDRS\" into \"combined_UPDRS\" as a feature engineering step. This simplifies the target variable for regression modeling.\n",
    "\n",
    "\n",
    "Model Evaluation:\n",
    "\n",
    "I used evaluation metrics (MSE, RMSE, MAE, R2) to gain insights into the performance of different regression models, such as Linear Regression, Elastic Net, and Random Forest. Random Forest Regression appeared to perform well, especially based on the R2 score.\n",
    "\n",
    "\n",
    "Feature Importance:\n",
    "\n",
    "Analyzing feature importance, particularly the bar chart, helped me identify the features that contribute the most to the model's predictions. Age stood out as the most important feature, aligning with the understanding that Parkinson's disease is more common in older individuals.\n",
    "\n",
    "## Best performing scenario till now: Random Forest Regressor, after applying Feature Importance\n",
    "\n",
    "\n",
    "Visualization:\n",
    "\n",
    "I created scatter plots, strip plots, and pair plots to visually represent relationships between different variables. These visualizations are crucial for my understanding of the patterns in the data.\n",
    "\n",
    "\n",
    "Decision Tree Visualization:\n",
    "\n",
    "Visualizing decision trees from the random forest models provided insights into how the model makes predictions. This was helpful for interpretability.\n",
    "\n",
    "\n",
    "Model Comparison:\n",
    "\n",
    "I compared the performance of Linear Regression, Elastic Net, and Random Forest Regression. It's important to consider the trade-offs between model complexity and performance.\n",
    "\n",
    "\n",
    "Avoiding Feature Combination:\n",
    "\n",
    "I chose not to combine all jitter variables into one, considering the slight degradation in the performance of the Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "8QgztFGOEk7Q",
    "outputId": "5de54392-02dd-4a25-f1de-242e88e691cc"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.core.display import Image\n",
    "import graphviz\n",
    "\n",
    "for i in range(1):\n",
    "    tree = rfr.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,\n",
    "                               filled=True,\n",
    "                               max_depth=6,\n",
    "                               impurity=False,\n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjXNwxM4JGh6",
    "outputId": "15be9ed0-ad43-432f-e668-486f47f0aea9"
   },
   "outputs": [],
   "source": [
    "! pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "an3CCNHrzkvq",
    "outputId": "1f1e7e2e-2188-4d6b-f3eb-3e3d26f904e7"
   },
   "outputs": [],
   "source": [
    "! pip install nolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def calculate_dfa_exponent_1(audio_file_path, window_size=500):\n",
    "    # Load audio file and extract waveform and sampling rate\n",
    "    audio_data, sr = librosa.load(audio_file_path)\n",
    "\n",
    "    # Calculate integrated series (cumulative sum of detrended audio data)\n",
    "    integrated_series = np.cumsum(audio_data - np.mean(audio_data))\n",
    "\n",
    "    # Calculate RMS values over windows of specified size\n",
    "    num_windows = len(integrated_series) // window_size\n",
    "    windows = np.array_split(integrated_series[:num_windows * window_size], num_windows)\n",
    "    window_rms = [np.sqrt(np.mean(window**2)) for window in windows]\n",
    "\n",
    "    # Compute log-log relationship to estimate DFA exponent (alpha)\n",
    "    n_values = np.arange(1, num_windows + 1) * window_size\n",
    "    F_n_values = np.array(window_rms)\n",
    "    log_n = np.log(n_values)\n",
    "    log_F_n = np.log(F_n_values)\n",
    "    \n",
    "    # Use linear regression to estimate scaling exponent (alpha)\n",
    "    slope, _ = np.polyfit(log_n, log_F_n, 1)\n",
    "    alpha = slope  # DFA exponent (scaling exponent)\n",
    "    \n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = './PD_AH/AH_545643618-82A143AC-B643-4273-A923-C42A83AEEC5F.wav'\n",
    "alpha = calculate_dfa_exponent_1(audio_file_path,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gxPg_Zr3RDv",
    "outputId": "74db0a69-e012-42fe-a863-7a8e321410dd"
   },
   "outputs": [],
   "source": [
    "! pip install fathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "KFZT-VpEEk7U",
    "outputId": "94c56fe9-4785-45ed-b386-1ad449f81ed2"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    sound = parselmouth.Sound(voiceID)\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max)\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit)\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit)\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "\n",
    "\n",
    "    return meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer\n",
    "\n",
    "\n",
    "file_list = []\n",
    "mean_F0_list = []\n",
    "sd_F0_list = []\n",
    "hnr_list = []\n",
    "localJitter_list = []\n",
    "localabsoluteJitter_list = []\n",
    "rapJitter_list = []\n",
    "ppq5Jitter_list = []\n",
    "ddpJitter_list = []\n",
    "localShimmer_list = []\n",
    "localdbShimmer_list = []\n",
    "apq3Shimmer_list = []\n",
    "aqpq5Shimmer_list = []\n",
    "apq11Shimmer_list = []\n",
    "ddaShimmer_list = []\n",
    "\n",
    "for wave_file in glob.glob('./PD_AH/AH_545643618-82A143AC-B643-4273-A923-C42A83AEEC5F.wav'):\n",
    "    sound = parselmouth.Sound(wave_file)\n",
    "    (meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer) = measurePitch(sound, 75, 500, \"Hertz\")\n",
    "    file_list.append(wave_file)\n",
    "    mean_F0_list.append(meanF0)\n",
    "    sd_F0_list.append(stdevF0)\n",
    "    hnr_list.append(hnr)\n",
    "    localJitter_list.append(localJitter)\n",
    "    localabsoluteJitter_list.append(localabsoluteJitter)\n",
    "    rapJitter_list.append(rapJitter)\n",
    "    ppq5Jitter_list.append(ppq5Jitter)\n",
    "    ddpJitter_list.append(ddpJitter)\n",
    "    localShimmer_list.append(localShimmer)\n",
    "    localdbShimmer_list.append(localdbShimmer)\n",
    "    apq3Shimmer_list.append(apq3Shimmer)\n",
    "    aqpq5Shimmer_list.append(aqpq5Shimmer)\n",
    "    apq11Shimmer_list.append(apq11Shimmer)\n",
    "    ddaShimmer_list.append(ddaShimmer)\n",
    "df = pd.DataFrame(np.column_stack([file_list, mean_F0_list, sd_F0_list, hnr_list, localJitter_list, localabsoluteJitter_list, rapJitter_list, ppq5Jitter_list, ddpJitter_list, localShimmer_list, localdbShimmer_list, apq3Shimmer_list, aqpq5Shimmer_list, apq11Shimmer_list, ddaShimmer_list]),\n",
    "                               columns=['voiceID', 'meanF0Hz', 'stdevF0Hz', 'HNR', 'localJitter', 'localabsoluteJitter', 'rapJitter',\n",
    "                                        'ppq5Jitter', 'ddpJitter', 'localShimmer', 'localdbShimmer', 'apq3Shimmer', 'apq5Shimmer',\n",
    "                                        'apq11Shimmer', 'ddaShimmer'])\n",
    "\n",
    "df.to_csv(\"processed_results.csv\", index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sATgsWH5nkQ",
    "outputId": "70ab8aa1-e978-4c14-8289-4d18c90d25df"
   },
   "outputs": [],
   "source": [
    "model = rfr_top\n",
    "import pickle\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    sound = parselmouth.Sound(voiceID)\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max)\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit)\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit)\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "\n",
    "    return hnr, localabsoluteJitter\n",
    "\n",
    "\n",
    "def predict_jitter_shimmer(audio_file):\n",
    "    age_ip = input(\"Enter your age: \")\n",
    "    sex_ip = input(\"Enter your sex: (0 for male, 1 for female): \")\n",
    "\n",
    "    sound = parselmouth.Sound(audio_file)\n",
    "    hnr, localabsoluteJitter = measurePitch(sound, 75, 500, \"Hertz\")\n",
    "    top_5 = ['age', 'DFA', 'sex', 'Jitter(Abs)', 'HNR']\n",
    "    features = [age_ip, alpha, sex_ip, localabsoluteJitter, hnr]  # Assuming alpha is defined somewhere\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    prediction = model.predict([features])\n",
    "    return prediction\n",
    "\n",
    "\n",
    "audio_file = './PD_AH/AH_545789671-794D2256-DDFF-4009-8BA8-8A306C8FA14F.wav'\n",
    "prediction = predict_jitter_shimmer(audio_file)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eRfxzfZEk7b"
   },
   "outputs": [],
   "source": [
    "if prediction > 29:\n",
    "    print(\"person has parkinson\")\n",
    "else:\n",
    "    print(\"person does not have parkinson\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzF4zDs2Ek7d"
   },
   "outputs": [],
   "source": [
    "def calculate_nhr_ppe(audio_file):\n",
    "    sound = parselmouth.Sound(audio_file)\n",
    "    \n",
    "    # NHR Calculation\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    nhr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    \n",
    "    # PPE Calculation\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 500)\n",
    "    ppe = call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    \n",
    "    return nhr, ppe\n",
    "\n",
    "# Example usage:\n",
    "audio_file = './HC_AH/AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav'\n",
    "nhr, ppe = calculate_nhr_ppe(audio_file)\n",
    "print(\"NHR:\", nhr)\n",
    "print(\"PPE:\", ppe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zgIwTN9Ek7j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parselmouth\n",
    "import pickle\n",
    "from parselmouth.praat import call\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "\n",
    "model = rfr_top\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "def list_audio_samples(folder_path):\n",
    "    audio_samples = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "    return audio_samples\n",
    "\n",
    "folder_path = \"./PD_AH\"\n",
    "audio_list = list_audio_samples(folder_path)\n",
    "\n",
    "def measurePitch(voiceID, f0min, f0max, unit):\n",
    "    sound = parselmouth.Sound(voiceID)\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max)\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit)\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0, 0, unit)\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    return hnr, localabsoluteJitter\n",
    "\n",
    "def predict_jitter_shimmer(audio_list, excel_data):\n",
    "    predictions = []\n",
    "    model = pickle.load(open(filename, 'rb'))  \n",
    "    pwpd_rows = excel_data[excel_data['Label'] == 'PwPD']\n",
    "    \n",
    "    for audio_file in audio_list:\n",
    "        sound = parselmouth.Sound(audio_file)\n",
    "        hnr, local_absolute_jitter = measurePitch(sound, 75, 500, \"Hertz\")\n",
    "        file_name_1 = os.path.basename(audio_file)\n",
    "        parts = file_name_1.split('.')\n",
    "        file_name = parts[0]\n",
    "\n",
    "        row = pwpd_rows.loc[pwpd_rows['Sample_ID'] == file_name]\n",
    "\n",
    "        if not row.empty:\n",
    "            age = row['Age'].values[0]\n",
    "            sex = row['Sex'].values[0]\n",
    "            if sex == 'M':\n",
    "                sex = 0\n",
    "            else:\n",
    "                sex = 1\n",
    "            features = [age, alpha, sex, local_absolute_jitter, hnr] \n",
    "            prediction = model.predict([features])\n",
    "            predictions.append(prediction[0])  # Assuming the model returns a list/array, so taking the first element\n",
    "    return predictions\n",
    "\n",
    "excel_file_path = r\"Demographics_age_sex.xlsx\"\n",
    "\n",
    "def load_excel_data(excel_file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "    except PermissionError as e:\n",
    "        print(f\"Permission error: {e}\")\n",
    "        raise\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "    return df\n",
    "\n",
    "excel_data = load_excel_data(excel_file_path)\n",
    "\n",
    "def compute_threshold_pwPD(audio_samples, excel_data):\n",
    "    predictions = predict_jitter_shimmer(audio_samples, excel_data)\n",
    "    metrics_pwPD = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        file_name = os.path.basename(audio_samples[i])\n",
    "        parts = file_name.split('.')\n",
    "        file_name = parts[0]\n",
    "\n",
    "        row = excel_data.loc[excel_data['Sample_ID'] == file_name]\n",
    "        if not row.empty:\n",
    "            label = row['Label'].values[0]\n",
    "            if label == 'PwPD':\n",
    "                metrics_pwPD.append(prediction)\n",
    "            elif label != 'HC':\n",
    "                print(f\"Unknown label '{label}' for file: {file_name}\")\n",
    "    if metrics_pwPD:\n",
    "        threshold_pwPD = np.mean(metrics_pwPD)\n",
    "    else:\n",
    "        threshold_pwPD = None\n",
    "    return threshold_pwPD\n",
    "\n",
    "audio_samples = list_audio_samples(folder_path)\n",
    "threshold_pwPD = compute_threshold_pwPD(audio_samples, excel_data)\n",
    "print(f\"The threshold value for PwPD is: {threshold_pwPD}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
